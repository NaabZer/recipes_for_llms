{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7ac8e4-76e5-4004-981e-40d17aedbe6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543fe956-e555-4079-830b-5e0228d2b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Quantity', 'Unit', 'Food', 'Variety', 'Preparation', 'Alteration', 'Brand', 'Optional', 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5010a646-70e2-448e-8341-654c45a7485d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ner_ds = pd.read_json(\"../../data/NER_data/ner_ls_1_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8b30da-5a5a-40ad-87c4-e14afdbe8386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>file_upload</th>\n",
       "      <th>drafts</th>\n",
       "      <th>predictions</th>\n",
       "      <th>data</th>\n",
       "      <th>meta</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>inner_id</th>\n",
       "      <th>total_annotations</th>\n",
       "      <th>cancelled_annotations</th>\n",
       "      <th>total_predictions</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unresolved_comment_count</th>\n",
       "      <th>last_comment_updated_at</th>\n",
       "      <th>project</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>comment_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 2, 'completed_by': 1, 'result': [{'val...</td>\n",
       "      <td>2249c960-label_s_tasteset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'id': 2101, 'text': '5 ounces rum\n",
       "4 ounces tr...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-05-14 14:24:58.753961+00:00</td>\n",
       "      <td>2025-05-14 14:25:08.674942+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 3, 'completed_by': 1, 'result': [{'val...</td>\n",
       "      <td>2249c960-label_s_tasteset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>{'id': 2102, 'text': '2 tubes cinnamon roll, r...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-05-14 14:24:58.754033+00:00</td>\n",
       "      <td>2025-05-14 14:29:18.588099+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'id': 4, 'completed_by': 1, 'result': [{'val...</td>\n",
       "      <td>2249c960-label_s_tasteset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>{'id': 2103, 'text': '4 ripe coconuts\n",
       "1 cup ev...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-05-14 14:24:58.754070+00:00</td>\n",
       "      <td>2025-05-14 14:30:25.910344+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'id': 5, 'completed_by': 1, 'result': [{'val...</td>\n",
       "      <td>2249c960-label_s_tasteset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>{'id': 2104, 'text': '1 sheet graham cracker (...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-05-14 14:24:58.754104+00:00</td>\n",
       "      <td>2025-05-14 14:31:26.031006+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[{'id': 6, 'completed_by': 1, 'result': [{'val...</td>\n",
       "      <td>2249c960-label_s_tasteset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>{'id': 2105, 'text': '1 (8 ounce) package cres...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-05-14 14:24:58.754139+00:00</td>\n",
       "      <td>2025-05-14 14:32:23.664759+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        annotations  \\\n",
       "0   1  [{'id': 2, 'completed_by': 1, 'result': [{'val...   \n",
       "1   2  [{'id': 3, 'completed_by': 1, 'result': [{'val...   \n",
       "2   3  [{'id': 4, 'completed_by': 1, 'result': [{'val...   \n",
       "3   4  [{'id': 5, 'completed_by': 1, 'result': [{'val...   \n",
       "4   5  [{'id': 6, 'completed_by': 1, 'result': [{'val...   \n",
       "\n",
       "                      file_upload drafts predictions  \\\n",
       "0  2249c960-label_s_tasteset.json     []         [1]   \n",
       "1  2249c960-label_s_tasteset.json     []         [2]   \n",
       "2  2249c960-label_s_tasteset.json     []         [3]   \n",
       "3  2249c960-label_s_tasteset.json     []         [4]   \n",
       "4  2249c960-label_s_tasteset.json     []         [5]   \n",
       "\n",
       "                                                data meta  \\\n",
       "0  {'id': 2101, 'text': '5 ounces rum\n",
       "4 ounces tr...   {}   \n",
       "1  {'id': 2102, 'text': '2 tubes cinnamon roll, r...   {}   \n",
       "2  {'id': 2103, 'text': '4 ripe coconuts\n",
       "1 cup ev...   {}   \n",
       "3  {'id': 2104, 'text': '1 sheet graham cracker (...   {}   \n",
       "4  {'id': 2105, 'text': '1 (8 ounce) package cres...   {}   \n",
       "\n",
       "                        created_at                       updated_at  inner_id  \\\n",
       "0 2025-05-14 14:24:58.753961+00:00 2025-05-14 14:25:08.674942+00:00         1   \n",
       "1 2025-05-14 14:24:58.754033+00:00 2025-05-14 14:29:18.588099+00:00         2   \n",
       "2 2025-05-14 14:24:58.754070+00:00 2025-05-14 14:30:25.910344+00:00         3   \n",
       "3 2025-05-14 14:24:58.754104+00:00 2025-05-14 14:31:26.031006+00:00         4   \n",
       "4 2025-05-14 14:24:58.754139+00:00 2025-05-14 14:32:23.664759+00:00         5   \n",
       "\n",
       "   total_annotations  cancelled_annotations  total_predictions  comment_count  \\\n",
       "0                  1                      0                  1              0   \n",
       "1                  1                      0                  1              0   \n",
       "2                  1                      0                  1              0   \n",
       "3                  1                      0                  1              0   \n",
       "4                  1                      0                  1              0   \n",
       "\n",
       "   unresolved_comment_count last_comment_updated_at  project  updated_by  \\\n",
       "0                         0                     NaT        1           1   \n",
       "1                         0                     NaT        1           1   \n",
       "2                         0                     NaT        1           1   \n",
       "3                         0                     NaT        1           1   \n",
       "4                         0                     NaT        1           1   \n",
       "\n",
       "  comment_authors  \n",
       "0              []  \n",
       "1              []  \n",
       "2              []  \n",
       "3              []  \n",
       "4              []  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ca0220-1a62-4d54-a163-15d489cd2edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'start': 0, 'end': 1, 'text': '5', 'labels': ['Quantity']},\n",
       "  'id': 'vPB1zoFJIh',\n",
       "  'from_name': 'label',\n",
       "  'to_name': 'text',\n",
       "  'type': 'labels',\n",
       "  'origin': 'prediction'},\n",
       " {'value': {'start': 2, 'end': 8, 'text': 'ounces', 'labels': ['Unit']},\n",
       "  'id': 'R6fjr7ZVsn',\n",
       "  'from_name': 'label',\n",
       "  'to_name': 'text',\n",
       "  'type': 'labels',\n",
       "  'origin': 'prediction'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_ds.iloc[0]['annotations'][0]['result'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67a3414-2eb6-4b15-8cb7-60436f3d092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def doc_from_ds(ds):\n",
    "    db = DocBin()\n",
    "    for i, [data, annotation] in ds[['data', 'annotations']].iterrows():\n",
    "        try:\n",
    "            text = data['text']\n",
    "            annotation_data = annotation[0]['result']\n",
    "            doc = nlp.make_doc(text)\n",
    "            annotation_entities = [\n",
    "                (annotation['value']['start'],\n",
    "                annotation['value']['end'],\n",
    "                annotation['value']['labels'][0])\n",
    "                for annotation in annotation_data]\n",
    "            entities = [doc.char_span(*ents)\n",
    "                        for ents in annotation_entities]\n",
    "            #entities = [doc.char_span(\n",
    "            #    start=annotation['value']['start'],\n",
    "            #    end=annotation['value']['end'],\n",
    "            #    label=annotation['value']['labels'][0]\n",
    "            #) for annotation in annotation_data]\n",
    "            doc.ents = entities\n",
    "            db.add(doc)\n",
    "        except TypeError as e:\n",
    "            print(f\"error at index {i}: {e}\")\n",
    "            continue\n",
    "    return db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c289ddf3-7c12-4590-88d4-eb93d7a15d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                        163\n",
       "annotations                 [{'id': 164, 'completed_by': 1, 'result': [{'v...\n",
       "file_upload                                    2249c960-label_s_tasteset.json\n",
       "drafts                                                                     []\n",
       "predictions                                                        [163, 705]\n",
       "data                        {'id': 2263, 'text': '32 large marshmallows (1...\n",
       "meta                                                                       {}\n",
       "created_at                                   2025-05-14 14:24:58.762914+00:00\n",
       "updated_at                                   2025-05-15 22:33:11.694169+00:00\n",
       "inner_id                                                                  163\n",
       "total_annotations                                                           1\n",
       "cancelled_annotations                                                       0\n",
       "total_predictions                                                           2\n",
       "comment_count                                                               0\n",
       "unresolved_comment_count                                                    0\n",
       "last_comment_updated_at                                                   NaT\n",
       "project                                                                     1\n",
       "updated_by                                                                  1\n",
       "comment_authors                                                            []\n",
       "Name: 162, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_ds.iloc[162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce96f0a-948b-4126-9b96-6cfa1df9b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def ds_to_data_split(ds, train_size=0.8, random_state=123):\n",
    "    train_ds, val_ds = train_test_split(ds, train_size=train_size, random_state=random_state)\n",
    "    train_bin = doc_from_ds(train_ds)\n",
    "    val_bin = doc_from_ds(val_ds)\n",
    "\n",
    "    return train_bin, val_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c432a45-ea5b-4372-a498-0c14f78bb050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error at index 306: object of type 'NoneType' has no len()\n",
      "error at index 59: object of type 'NoneType' has no len()\n",
      "error at index 682: object of type 'NoneType' has no len()\n",
      "error at index 163: object of type 'NoneType' has no len()\n",
      "error at index 122: object of type 'NoneType' has no len()\n",
      "error at index 242: object of type 'NoneType' has no len()\n",
      "error at index 469: object of type 'NoneType' has no len()\n",
      "error at index 378: object of type 'NoneType' has no len()\n",
      "error at index 201: object of type 'NoneType' has no len()\n",
      "error at index 184: object of type 'NoneType' has no len()\n",
      "error at index 690: object of type 'NoneType' has no len()\n",
      "error at index 219: object of type 'NoneType' has no len()\n",
      "error at index 842: object of type 'NoneType' has no len()\n",
      "error at index 62: object of type 'NoneType' has no len()\n",
      "error at index 29: object of type 'NoneType' has no len()\n",
      "error at index 126: object of type 'NoneType' has no len()\n",
      "error at index 341: object of type 'NoneType' has no len()\n",
      "error at index 490: object of type 'NoneType' has no len()\n",
      "error at index 472: object of type 'NoneType' has no len()\n",
      "error at index 364: object of type 'NoneType' has no len()\n",
      "error at index 342: object of type 'NoneType' has no len()\n",
      "error at index 555: object of type 'NoneType' has no len()\n",
      "error at index 418: object of type 'NoneType' has no len()\n",
      "error at index 706: object of type 'NoneType' has no len()\n",
      "error at index 794: object of type 'NoneType' has no len()\n",
      "error at index 202: object of type 'NoneType' has no len()\n",
      "error at index 162: object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "train_bin, val_bin =  ds_to_data_split(ner_ds)\n",
    "train_path = \"../../data/NER_data/spacy/test_train.spacy\"\n",
    "val_path = \"../../data/NER_data/spacy/test_val.spacy\"\n",
    "train_bin.to_disk(train_path)\n",
    "val_bin.to_disk(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7d22d0-5bde-4ac8-b514-b4424cd1836b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca12fdfa-010e-4caf-95bb-6cacb4cd58c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def gen_config(train_path: str, dev_path:str, train_log_path: str, out_path: str):\n",
    "    BASE_CONFIG = f\"\"\"[paths]\n",
    "    train = {train_path}\n",
    "    dev = {dev_path}\n",
    "    vectors = null\n",
    "    \n",
    "    [system]\n",
    "    gpu_allocator = null\n",
    "    \n",
    "    [nlp]\n",
    "    lang = \"en\"\n",
    "    #pipeline = [\"tok2vec\", \"tagger\", \"attribute_ruler\", \"lemmatizer\", \"ner\"]\n",
    "    pipeline = [\"tok2vec\", \"ner\"]\n",
    "    batch_size = 1000\n",
    "    \n",
    "    [components]\n",
    "    \n",
    "    [components.tok2vec]\n",
    "    #source = \"en_core_web_sm\"\n",
    "    #component = \"tok2vec\"\n",
    "    factory = \"tok2vec\"\n",
    "    \n",
    "    [components.tok2vec.model]\n",
    "    @architectures = \"spacy.Tok2Vec.v2\"\n",
    "    \n",
    "    [components.tok2vec.model.embed]\n",
    "    @architectures = \"spacy.MultiHashEmbed.v2\"\n",
    "    width = ${{components.tok2vec.model.encode.width}}\n",
    "    attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"]\n",
    "    rows = [5000, 1000, 2500, 2500]\n",
    "    include_static_vectors = false\n",
    "    \n",
    "    [components.tok2vec.model.encode]\n",
    "    @architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
    "    width = 96\n",
    "    depth = 4\n",
    "    window_size = 1\n",
    "    maxout_pieces = 3\n",
    "\n",
    "    #[components.tagger]\n",
    "    #source = \"en_core_web_sm\"\n",
    "    #component = \"tagger\"\n",
    "\n",
    "    #[components.attribute_ruler]\n",
    "    #source = \"en_core_web_sm\"\n",
    "    #component = \"attribute_ruler\"\n",
    "\n",
    "    #[components.lemmatizer]\n",
    "    #source = \"en_core_web_sm\"\n",
    "    #component = \"lemmatizer\"\n",
    "    \n",
    "    [components.ner]\n",
    "    factory = \"ner\"\n",
    "    \n",
    "    [components.ner.model]\n",
    "    @architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "    state_type = \"ner\"\n",
    "    extra_state_tokens = false\n",
    "    hidden_width = 64\n",
    "    maxout_pieces = 2\n",
    "    use_upper = true\n",
    "    nO = null\n",
    "    \n",
    "    [components.ner.model.tok2vec]\n",
    "    @architectures = \"spacy.Tok2VecListener.v1\"\n",
    "    width = ${{components.tok2vec.model.encode.width}}\n",
    "    #width = 96\n",
    "    \n",
    "    [corpora]\n",
    "    \n",
    "    [corpora.train]\n",
    "    @readers = \"spacy.Corpus.v1\"\n",
    "    path = ${{paths.train}}\n",
    "    max_length = 0\n",
    "    \n",
    "    [corpora.dev]\n",
    "    @readers = \"spacy.Corpus.v1\"\n",
    "    path = ${{paths.dev}}\n",
    "    max_length = 0\n",
    "    \n",
    "    [training]\n",
    "    dev_corpus = \"corpora.dev\"\n",
    "    train_corpus = \"corpora.train\"\n",
    "    #frozen_components = [\"tok2vec\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"]\n",
    "    #annotating_components = [\"tok2vec\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"]\n",
    "\n",
    "    \n",
    "    [training.optimizer]\n",
    "    @optimizers = \"Adam.v1\"\n",
    "    \n",
    "    [training.batcher]\n",
    "    @batchers = \"spacy.batch_by_words.v1\"\n",
    "    discard_oversize = false\n",
    "    tolerance = 0.2\n",
    "    \n",
    "    [training.batcher.size]\n",
    "    @schedules = \"compounding.v1\"\n",
    "    start = 100\n",
    "    stop = 1000\n",
    "    compound = 1.001\n",
    "    \n",
    "    [initialize]\n",
    "    init_pipeline = \"en_core_web_sm\"\n",
    "    #vectors = ${{paths.vectors}}\n",
    "    \n",
    "    [training.logger]\n",
    "    @loggers = \"spacy.ConsoleLogger.v3\"\n",
    "    progress_bar = \"eval\"\n",
    "    console_output = true\n",
    "    output_file = {train_log_path}\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"temp.cfg\", 'w') as f:\n",
    "      f.write(BASE_CONFIG)\n",
    "    subprocess.call(['python', '-m', 'spacy', 'init', 'fill-config', 'temp.cfg', out_path])\n",
    "    os.remove('temp.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c85335-f7c5-47e6-98a9-0f85edbbe32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "log_path = \"train_log.jsonl\"\n",
    "cfg_path = \"config.cfg\"\n",
    "gen_config(train_path, val_path, log_path, cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d92e214e-c084-4d14-abf1-295a52e5565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import mlflow\n",
    "import mlflow.spacy\n",
    "from pathlib import Path\n",
    "import json\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.cli.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37ec8f4b-8d40-4bbd-8d73-474e85821728",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ner(model_dir: Path, config_path: Path):\n",
    "    train(config_path, model_dir)\n",
    "    nlp = spacy.load(Path(model_dir) / 'model-best')\n",
    "    \n",
    "    mlflow.log_artifact(config_path)\n",
    "    mlflow.spacy.log_model(spacy_model=nlp, artifact_path=\"model\")\n",
    "    mlflow.set_tag('model_flavor', 'spacy')\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model\"\n",
    "    return(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1242c74-1e64-4ad0-851a-d0c81b4ce76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def plot_conf_mat(model_uri: str, val_path: Path):\n",
    "    nlp = mlflow.spacy.load_model(model_uri=model_uri)\n",
    "    test_set = list(DocBin().from_disk(val_path).get_docs(nlp.vocab))\n",
    "    pred_ents = []\n",
    "    true_ents = []\n",
    "    \n",
    "    for recipe in test_set:\n",
    "      # tok.ent_type_ gets the ent per token, as opposed to breaking the Doc into\n",
    "      # entities. This ensures that `true_ents` and `pred_ents` are the same length.\n",
    "      true_ents += [tok.ent_type_ for tok in recipe]\n",
    "      # `recipe.text` grabs the raw recipe, because `recipe` already contains entity\n",
    "      # labels.\n",
    "      pred_ents += [tok.ent_type_ for tok in nlp(recipe.text)]\n",
    "    # create and display the confusion matrix\n",
    "    cm = confusion_matrix(true_ents, pred_ents, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    f = disp.plot(xticks_rotation=70).figure_\n",
    "    mlflow.log_figure(f, 'plots/confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15f4a54-9b96-42d5-975f-8c5c09616b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(model_uri: str, train_log_path: Path, val_path: Path):\n",
    "    mlflow.log_artifact(train_log_path)\n",
    "    with open(train_log_path) as f:\n",
    "        for line in f:\n",
    "            line_data = json.loads(line)\n",
    "            if line_data['step'] == 0:\n",
    "                continue\n",
    "            step = line_data['step']\n",
    "            for key, value in line_data['losses'].items():\n",
    "                mlflow.log_metric(f\"loss_{key}\", value, step)\n",
    "            for key, value in line_data['scores'].items():\n",
    "                mlflow.log_metric(f\"score_{key}\", value, step)\n",
    "            mlflow.log_metric(f\"score\", line_data['score'], step)\n",
    "    plot_conf_mat(model_uri, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a361d0-d285-45e5-9f2c-3f0ae1a1b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlflow_pipe(train_path: Path, val_path: Path, model_dir: Path, config_path: Path, train_log_path: Path):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URL\"))\n",
    "    mlflow.set_experiment(\"jupyter_NER\")\n",
    "    if os.path.exists(train_log_path):\n",
    "        os.remove(train_log_path)\n",
    "    with mlflow.start_run(run_name=\"jupyer_test\") as run:\n",
    "        model_uri = train_ner(model_dir, config_path)\n",
    "        log_metrics(model_uri, train_log_path, val_path)\n",
    "    return model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5855556-4a8a-4d3c-8546-2a6d08095a4f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output_eff\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving results to train_log.jsonl\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     50.74   19.77   16.19   25.37    0.20\n"
     ]
    }
   ],
   "source": [
    "model_uri = run_mlflow_pipe(train_path, val_path, \"output_eff/\", cfg_path, log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220d955-3e9f-4da7-bb05-09e0cd624844",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = mlflow.spacy.load_model(model_uri=model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acfb96-18b1-428c-86c8-5d465b8aeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = list(DocBin().from_disk(val_path).get_docs(nlp.vocab))\n",
    "pred_ents = []\n",
    "true_ents = []\n",
    "\n",
    "for recipe in test_set:\n",
    "    # tok.ent_type_ gets the ent per token, as opposed to breaking the Doc into\n",
    "    # entities. This ensures that `true_ents` and `pred_ents` are the same length.\n",
    "    true_ents += [tok.ent_type_ for tok in recipe]\n",
    "    # `recipe.text` grabs the raw recipe, because `recipe` already contains entity\n",
    "    # labels.\n",
    "    pred_ents += [tok.ent_type_ for tok in nlp(recipe.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599619fc-5015-4cc9-853e-ab03bcd84e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# create and display the confusion matrix\n",
    "cm = confusion_matrix(true_ents, pred_ents, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "fig = disp.plot(xticks_rotation=70)\n",
    "#fig.figure_.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed5ac8c-1aba-4c48-a307-14072eeb3530",
   "metadata": {},
   "source": [
    "### Testing on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450dc3ad-1d47-47bc-82cb-c9c84e71d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlg_ds = pd.read_csv('../../data/recipenlg/RecipeNLG_dataset.csv', converters={'ingredients': pd.eval}, nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742ca62-db32-49a5-81d4-6d5c65db2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlg_ds.head()\n",
    "ingredient_texts = []\n",
    "for ingredient in nlg_ds['ingredients']:\n",
    "    ingredient_texts.append(nlp(\"\\n\".join(ingredient)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09f125-5491-4ac6-882b-6fdd0ee4e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlg_ds.head()\n",
    "ingredient_texts = []\n",
    "for ingredient in nlg_ds['ingredients']:\n",
    "    ing = [nlp(i) for i in ingredient]\n",
    "    ingredient_texts += ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17279f-102e-48b9-9e33-78980ddf6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca5f32-0cd6-425c-9564-1b85efd01a4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "displacy.render(ingredient_texts, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7314aae-76bc-4c5e-bb95-32be03a2f1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
